{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Someone else is using the GPU, so I am using the CPU here.\n",
    "\n",
    "num_cores = 8\n",
    "\n",
    "CPU, GPU = True, False\n",
    "if GPU:\n",
    "    num_GPU = 1\n",
    "    num_CPU = 1\n",
    "if CPU:\n",
    "    num_CPU = 1\n",
    "    num_GPU = 0\n",
    "\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=num_cores,\\\n",
    "        inter_op_parallelism_threads=num_cores, allow_soft_placement=True,\\\n",
    "        device_count = {'CPU' : num_CPU, 'GPU' : num_GPU})\n",
    "session = tf.Session(config=config)\n",
    "K.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the file\n",
    "data = pd.read_csv('CASP.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=1, activation='linear', input_dim=9))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.loc[:, 'F1':'F9'].as_matrix()\n",
    "y = data.loc[:,'RMSD'].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 15.3 Âµs\n"
     ]
    }
   ],
   "source": [
    "% time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "#hyperparameters to search through with CV\n",
    "# helpful thing here? https://github.com/keras-team/keras/issues/4278\n",
    "# https://machinelearningmastery.com/use-keras-deep-learning-models-scikit-learn-python/\n",
    "\n",
    "parameters = {\n",
    "    'epochs' : [200, 400],\n",
    "    'batch_size' : [256,512], # The larger the batch size, the faster the model will run.\n",
    "        'verbose' : [0] # for debugging purpose. It will significantly lower the running speed. To speed up, change it to 0.\n",
    "}\n",
    "\n",
    "#searching through all combinations of parameters to find best (ranked by CV)\n",
    "reg = GridSearchCV(KerasRegressor(build_fn=baseline_model), parameters, cv = 5, scoring = 'neg_mean_squared_error', return_train_score = True)\n",
    "reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "results = cross_val_score(reg, X, y, cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -1828.95561056  -2406.42887063   -523.58724931  -1773.93858087\n",
      " -23802.79237422]\n"
     ]
    }
   ],
   "source": [
    "print (results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([20.3740963 , 41.11900005, 12.33722167, 25.06952462]),\n",
       " 'mean_score_time': array([0.02472973, 0.04610882, 0.06301317, 0.09294605]),\n",
       " 'mean_test_score': array([ -4534.65174027,   -200.72765929, -20068.10505265,  -2147.47085473]),\n",
       " 'mean_train_score': array([ -4538.62839445,   -199.4333615 , -21738.0645604 ,  -2187.69938223]),\n",
       " 'param_batch_size': masked_array(data=[256, 256, 512, 512],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_epochs': masked_array(data=[200, 400, 200, 400],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_verbose': masked_array(data=[0, 0, 0, 0],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'batch_size': 256, 'epochs': 200, 'verbose': 0},\n",
       "  {'batch_size': 256, 'epochs': 400, 'verbose': 0},\n",
       "  {'batch_size': 512, 'epochs': 200, 'verbose': 0},\n",
       "  {'batch_size': 512, 'epochs': 400, 'verbose': 0}],\n",
       " 'rank_test_score': array([3, 1, 4, 2], dtype=int32),\n",
       " 'split0_test_score': array([  -186.30925766,   -132.60212736, -42182.54933529,   -897.10878981]),\n",
       " 'split0_train_score': array([  -189.33740422,   -133.56455403, -52185.57168416,   -915.99896995]),\n",
       " 'split1_test_score': array([  -80.28058242,  -441.96505737, -1142.83376189, -5578.61949603]),\n",
       " 'split1_train_score': array([  -78.03557767,  -434.95682994, -1169.68569387, -5875.52967008]),\n",
       " 'split2_test_score': array([ -1125.44708406,   -251.13950221, -25797.94176524,  -2656.16159993]),\n",
       " 'split2_train_score': array([ -1097.24548546,   -255.19038104, -24935.13729524,  -2567.51082456]),\n",
       " 'split3_test_score': array([-18929.84186314,    -58.67198291, -29359.64232271,   -342.30861948]),\n",
       " 'split3_train_score': array([-18995.18672832,    -57.07223731, -28593.07399334,   -342.76644276]),\n",
       " 'split4_test_score': array([-2351.37991409,  -119.25962662, -1857.55807814, -1263.1557684 ]),\n",
       " 'split4_train_score': array([-2333.33677656,  -116.3828052 , -1806.85413539, -1236.69100382]),\n",
       " 'std_fit_time': array([0.11860528, 0.68489556, 0.27372896, 0.1213058 ]),\n",
       " 'std_score_time': array([0.00650047, 0.00784873, 0.00860413, 0.00686549]),\n",
       " 'std_test_score': array([ 7243.76084208,   135.79011729, 16112.12123876,  1878.06157694]),\n",
       " 'std_train_score': array([ 7273.39984741,   134.22587962, 18997.76027142,  1983.41954156])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["# https://stackoverflow.com/questions/40690598/can-keras-with-tensorflow-backend-be-forced-to-use-cpu-or-gpu-at-will"]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
