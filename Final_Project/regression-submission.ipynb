{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression models on the wine quality dataset\n",
    "\n",
    "In this notebook, we show how to use regression models to predict the wine quality in the wine quality dataset. \n",
    "In particular, we run regression models on the white wine dataset, but if we want to run experiment on the red wine dataset, it should be similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "red = pd.read_csv('winequality-red.csv', header=0)\n",
    "white = pd.read_csv('winequality-white.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
       "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
       "       'pH', 'sulphates', 'alcohol', 'quality'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the columns of the the data\n",
    "white.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find X and y for the white wine dataset\n",
    "whiteX = white.loc[:, 'fixed acidity': 'alcohol'].as_matrix()\n",
    "whitey = white.loc[:, 'quality'].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find X and y for the white wine dataset\n",
    "redX = red.loc[:, 'fixed acidity': 'alcohol'].as_matrix()\n",
    "redy = red.loc[:, 'quality'].as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First model: SVM\n",
    "\n",
    "We use the SVMregressor in sklearn, make sure to set up `max_iter` so the program does not take forever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "svr = SVR(max_iter=1000000, gamma=0.03, epsilon=0.1, C=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:  2.8min\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed: 11.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SVR(C=1, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=0.03,\n",
       "  kernel='rbf', max_iter=1000000, shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=8,\n",
       "       param_grid={'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'degree': [2, 3, 4, 5, 6]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='neg_mean_absolute_error', verbose=True)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_SVM = {'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'degree':[2,3,4,5,6]}\n",
    "SVM_grid = GridSearchCV(svr,  param_SVM, scoring = 'neg_mean_absolute_error', n_jobs=8, cv=5, verbose=True, return_train_score=True)\n",
    "SVM_grid.fit(whiteX, whitey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 26.44275041, 139.02047524,   1.95401397,   0.45022049,\n",
       "         33.03270149, 182.2554975 ,   2.15190535,   0.56166439,\n",
       "         38.67539644, 184.91105847,   1.93239598,   0.59925499,\n",
       "         39.91496577, 188.22781754,   2.12911825,   0.55905452,\n",
       "         40.96137075, 152.13425841,   1.87154036,   0.56012678]),\n",
       " 'mean_score_time': array([0.04879308, 0.12294068, 0.14000206, 0.05242782, 0.11315107,\n",
       "        0.10205355, 0.1967515 , 0.06241283, 0.10652165, 0.09881649,\n",
       "        0.18498449, 0.07589769, 0.10089107, 0.1041357 , 0.16071076,\n",
       "        0.05933366, 0.11529622, 0.05376692, 0.15313897, 0.06840892]),\n",
       " 'mean_test_score': array([-7.79333211e-01, -9.70428488e+00, -6.67113575e-01, -6.63495304e-01,\n",
       "        -7.79333211e-01, -1.41210332e+04, -6.67113575e-01, -6.63495304e-01,\n",
       "        -7.79333211e-01, -5.62139608e+06, -6.67113575e-01, -6.63495304e-01,\n",
       "        -7.79333211e-01, -8.83146508e+09, -6.67113575e-01, -6.63495304e-01,\n",
       "        -7.79333211e-01, -1.56651914e+13, -6.67113575e-01, -6.63495304e-01]),\n",
       " 'mean_train_score': array([-7.38023041e-01, -9.58209355e+00, -3.87025736e-01, -6.63493974e-01,\n",
       "        -7.38023041e-01, -1.40381408e+04, -3.87025736e-01, -6.63493974e-01,\n",
       "        -7.38023041e-01, -5.56743123e+06, -3.87025736e-01, -6.63493974e-01,\n",
       "        -7.38023041e-01, -9.37196747e+09, -3.87025736e-01, -6.63493974e-01,\n",
       "        -7.38023041e-01, -1.68529633e+13, -3.87025736e-01, -6.63493974e-01]),\n",
       " 'param_degree': masked_array(data=[2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6,\n",
       "                    6, 6],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_kernel': masked_array(data=['linear', 'poly', 'rbf', 'sigmoid', 'linear', 'poly',\n",
       "                    'rbf', 'sigmoid', 'linear', 'poly', 'rbf', 'sigmoid',\n",
       "                    'linear', 'poly', 'rbf', 'sigmoid', 'linear', 'poly',\n",
       "                    'rbf', 'sigmoid'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'degree': 2, 'kernel': 'linear'},\n",
       "  {'degree': 2, 'kernel': 'poly'},\n",
       "  {'degree': 2, 'kernel': 'rbf'},\n",
       "  {'degree': 2, 'kernel': 'sigmoid'},\n",
       "  {'degree': 3, 'kernel': 'linear'},\n",
       "  {'degree': 3, 'kernel': 'poly'},\n",
       "  {'degree': 3, 'kernel': 'rbf'},\n",
       "  {'degree': 3, 'kernel': 'sigmoid'},\n",
       "  {'degree': 4, 'kernel': 'linear'},\n",
       "  {'degree': 4, 'kernel': 'poly'},\n",
       "  {'degree': 4, 'kernel': 'rbf'},\n",
       "  {'degree': 4, 'kernel': 'sigmoid'},\n",
       "  {'degree': 5, 'kernel': 'linear'},\n",
       "  {'degree': 5, 'kernel': 'poly'},\n",
       "  {'degree': 5, 'kernel': 'rbf'},\n",
       "  {'degree': 5, 'kernel': 'sigmoid'},\n",
       "  {'degree': 6, 'kernel': 'linear'},\n",
       "  {'degree': 6, 'kernel': 'poly'},\n",
       "  {'degree': 6, 'kernel': 'rbf'},\n",
       "  {'degree': 6, 'kernel': 'sigmoid'}],\n",
       " 'rank_test_score': array([11, 16,  6,  1, 11, 17,  6,  1, 11, 18,  6,  1, 11, 19,  6,  1, 11,\n",
       "        20,  6,  1], dtype=int32),\n",
       " 'split0_test_score': array([-7.67537977e-01, -5.07084482e+00, -7.01534198e-01, -7.09795918e-01,\n",
       "        -7.67537977e-01, -1.34143154e+04, -7.01534198e-01, -7.09795918e-01,\n",
       "        -7.67537977e-01, -4.33956746e+06, -7.01534198e-01, -7.09795918e-01,\n",
       "        -7.67537977e-01, -9.74763661e+09, -7.01534198e-01, -7.09795918e-01,\n",
       "        -7.67537977e-01, -2.08941431e+13, -7.01534198e-01, -7.09795918e-01]),\n",
       " 'split0_train_score': array([-6.39063033e-01, -4.66407138e+00, -3.75128599e-01, -6.51914242e-01,\n",
       "        -6.39063033e-01, -1.20245595e+04, -3.75128599e-01, -6.51914242e-01,\n",
       "        -6.39063033e-01, -4.43315369e+06, -3.75128599e-01, -6.51914242e-01,\n",
       "        -6.39063033e-01, -9.84468158e+09, -3.75128599e-01, -6.51914242e-01,\n",
       "        -6.39063033e-01, -2.03793786e+13, -3.75128599e-01, -6.51914242e-01]),\n",
       " 'split1_test_score': array([-6.09232614e-01, -1.82276308e+01, -6.92587477e-01, -6.84081633e-01,\n",
       "        -6.09232614e-01, -1.13582189e+04, -6.92587477e-01, -6.84081633e-01,\n",
       "        -6.09232614e-01, -4.27261772e+06, -6.92587477e-01, -6.84081633e-01,\n",
       "        -6.09232614e-01, -4.18546115e+09, -6.92587477e-01, -6.84081633e-01,\n",
       "        -6.09232614e-01, -7.80528726e+12, -6.92587477e-01, -6.84081633e-01]),\n",
       " 'split1_train_score': array([-5.85482992e-01, -1.68665641e+01, -3.76575914e-01, -6.58346095e-01,\n",
       "        -5.85482992e-01, -1.06049897e+04, -3.76575914e-01, -6.58346095e-01,\n",
       "        -5.85482992e-01, -4.10057282e+06, -3.76575914e-01, -6.58346095e-01,\n",
       "        -5.85482992e-01, -4.11152436e+09, -3.76575914e-01, -6.58346095e-01,\n",
       "        -5.85482992e-01, -8.43271335e+12, -3.76575914e-01, -6.58346095e-01]),\n",
       " 'split2_test_score': array([-6.14754968e-01, -3.15170665e+00, -6.73740619e-01, -7.00816327e-01,\n",
       "        -6.14754968e-01, -1.48066017e+04, -6.73740619e-01, -7.00816327e-01,\n",
       "        -6.14754968e-01, -5.20093373e+06, -6.73740619e-01, -7.00816327e-01,\n",
       "        -6.14754968e-01, -4.73641515e+09, -6.73740619e-01, -7.00816327e-01,\n",
       "        -6.14754968e-01, -1.58437518e+13, -6.73740619e-01, -7.00816327e-01]),\n",
       " 'split2_train_score': array([-5.97903755e-01, -3.15003369e+00, -3.94952195e-01, -6.54160286e-01,\n",
       "        -5.97903755e-01, -1.41970258e+04, -3.94952195e-01, -6.54160286e-01,\n",
       "        -5.97903755e-01, -5.12101506e+06, -3.94952195e-01, -6.54160286e-01,\n",
       "        -5.97903755e-01, -5.34953978e+09, -3.94952195e-01, -6.54160286e-01,\n",
       "        -5.97903755e-01, -1.62028162e+13, -3.94952195e-01, -6.54160286e-01]),\n",
       " 'split3_test_score': array([-9.84602287e-01, -1.21691276e+01, -6.54901442e-01, -6.62410623e-01,\n",
       "        -9.84602287e-01, -2.06014300e+04, -6.54901442e-01, -6.62410623e-01,\n",
       "        -9.84602287e-01, -1.06988429e+07, -6.54901442e-01, -6.62410623e-01,\n",
       "        -9.84602287e-01, -1.51375944e+10, -6.54901442e-01, -6.62410623e-01,\n",
       "        -9.84602287e-01, -2.70476255e+13, -6.54901442e-01, -6.62410623e-01]),\n",
       " 'split3_train_score': array([-9.22829306e-01, -1.20875591e+01, -3.93245339e-01, -6.63766267e-01,\n",
       "        -9.22829306e-01, -2.14904677e+04, -3.93245339e-01, -6.63766267e-01,\n",
       "        -9.22829306e-01, -1.13176271e+07, -3.93245339e-01, -6.63766267e-01,\n",
       "        -9.22829306e-01, -1.72085946e+10, -3.93245339e-01, -6.63766267e-01,\n",
       "        -9.22829306e-01, -3.21167441e+13, -3.93245339e-01, -6.63766267e-01]),\n",
       " 'split4_test_score': array([-9.20892116e-01, -9.90483437e+00, -6.12736193e-01, -5.60265577e-01,\n",
       "        -9.20892116e-01, -1.04274437e+04, -6.12736193e-01, -5.60265577e-01,\n",
       "        -9.20892116e-01, -3.59813515e+06, -6.12736193e-01, -5.60265577e-01,\n",
       "        -9.20892116e-01, -1.03582109e+10, -6.12736193e-01, -5.60265577e-01,\n",
       "        -9.20892116e-01, -6.73765418e+12, -6.12736193e-01, -5.60265577e-01]),\n",
       " 'split4_train_score': array([-9.44836117e-01, -1.11422395e+01, -3.95226634e-01, -6.89282980e-01,\n",
       "        -9.44836117e-01, -1.18736613e+04, -3.95226634e-01, -6.89282980e-01,\n",
       "        -9.44836117e-01, -2.86478748e+06, -3.95226634e-01, -6.89282980e-01,\n",
       "        -9.44836117e-01, -1.03454970e+10, -3.95226634e-01, -6.89282980e-01,\n",
       "        -9.44836117e-01, -7.13316441e+12, -3.95226634e-01, -6.89282980e-01]),\n",
       " 'std_fit_time': array([1.39013402, 7.53196918, 0.36200399, 0.01612871, 4.99474417,\n",
       "        2.01987388, 0.2114814 , 0.12806373, 1.50966542, 3.27662084,\n",
       "        0.2154533 , 0.1049317 , 1.612351  , 4.70420187, 0.49558966,\n",
       "        0.07476482, 3.07300305, 8.69501405, 0.29416819, 0.10594099]),\n",
       " 'std_score_time': array([0.00984197, 0.00714788, 0.00067255, 0.00210706, 0.01318265,\n",
       "        0.01451719, 0.04531392, 0.02012574, 0.01441461, 0.020573  ,\n",
       "        0.06168175, 0.01985563, 0.02391653, 0.02422206, 0.0313281 ,\n",
       "        0.01321868, 0.0124031 , 0.0232004 , 0.02479841, 0.01713389]),\n",
       " 'std_test_score': array([1.53830105e-01, 5.35201570e+00, 3.15674416e-02, 5.40611599e-02,\n",
       "        1.53830105e-01, 3.58357862e+03, 3.15674416e-02, 5.40611599e-02,\n",
       "        1.53830105e-01, 2.58829346e+06, 3.15674416e-02, 5.40611599e-02,\n",
       "        1.53830105e-01, 4.03193738e+09, 3.15674416e-02, 5.40611599e-02,\n",
       "        1.53830105e-01, 7.72425882e+12, 3.15674416e-02, 5.40611599e-02]),\n",
       " 'std_train_score': array([1.61009297e-01, 5.04644944e+00, 9.15977723e-03, 1.35118879e-02,\n",
       "        1.61009297e-01, 3.90098522e+03, 9.15977723e-03, 1.35118879e-02,\n",
       "        1.61009297e-01, 2.96670128e+06, 9.15977723e-03, 1.35118879e-02,\n",
       "        1.61009297e-01, 4.61380818e+09, 9.15977723e-03, 1.35118879e-02,\n",
       "        1.61009297e-01, 9.06880809e+12, 9.15977723e-03, 1.35118879e-02])}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM_grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.6634953042058312, {'degree': 2, 'kernel': 'sigmoid'})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM_grid.best_score_, SVM_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-layer Perceptron Regressor\n",
    "\n",
    "Again, we use API from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed: 22.2min\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/local/AIUGA/jeremyshi/miniconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "[Parallel(n_jobs=8)]: Done 180 out of 180 | elapsed: 62.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=8,\n",
       "       param_grid={'learning_rate': ['invscaling', 'adaptive'], 'solver': ['lbfgs', 'sgd', 'adam'], 'hidden_layer_sizes': [(9000,), (4000,), (1000,)], 'activation': ['tanh', 'relu']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_absolute_error', verbose=True)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "MLP = MLPRegressor(early_stopping=True)\n",
    "param_MLP = {'learning_rate': ['invscaling', 'adaptive'], \n",
    "             'solver':['lbfgs', 'sgd', 'adam'],\n",
    "             'hidden_layer_sizes': [(9000, ), (4000, ), (1000, )],\n",
    "            'activation': ['tanh', 'relu']}\n",
    "MLP_grid = GridSearchCV(MLP, param_MLP,  cv=5, scoring = 'neg_mean_absolute_error', n_jobs=8, verbose=True)\n",
    "MLP_grid.fit(whiteX, whitey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5989539574396067,\n",
       " MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(9000,), learning_rate='invscaling',\n",
       "        learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False),\n",
       " {'activation': 'relu',\n",
       "  'hidden_layer_sizes': (9000,),\n",
       "  'learning_rate': 'invscaling',\n",
       "  'solver': 'lbfgs'})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP_grid.best_score_, MLP_grid.best_estimator_, MLP_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=8)]: Done  50 out of  50 | elapsed:    2.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=8,\n",
       "           oob_score=False, random_state=0, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=8,\n",
       "       param_grid={'max_depth': [1, 2, 3, 4, 5], 'n_estimators': [10, 50]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_absolute_error', verbose=True)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(random_state=0, n_jobs=8)\n",
    "param_rf = {'max_depth':[1,2,3,4,5], 'n_estimators': [10, 50]}\n",
    "rf_grid = GridSearchCV(rf, param_rf, cv=5, scoring = 'neg_mean_absolute_error', n_jobs=8, verbose=True)\n",
    "rf_grid.fit(whiteX, whitey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5864756244532766"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5, 'n_estimators': 50}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Regressor\n",
    "\n",
    "Based on our experiments, Gradient Boosting consistently gives remarkable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 273 candidates, totalling 1365 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 160 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=8)]: Done 662 tasks      | elapsed:   16.7s\n",
      "[Parallel(n_jobs=8)]: Done 952 tasks      | elapsed:   41.9s\n",
      "[Parallel(n_jobs=8)]: Done 1302 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=8)]: Done 1365 out of 1365 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=8,\n",
       "       param_grid={'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 20], 'n_estimators': [12, 18, 22, 25, 30, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 50, 55, 60, 65, 70]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_absolute_error', verbose=True)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gb = GradientBoostingRegressor()\n",
    "param_gb = {'max_depth':[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 20], 'n_estimators': [12, 18, 22, 25, 30, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 50, 55, 60, 65, 70]}\n",
    "gb_grid = GridSearchCV(gb, param_gb, cv=5, scoring = 'neg_mean_absolute_error', n_jobs=8, verbose=True)\n",
    "gb_grid.fit(whiteX, whitey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.574935677964577"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 4, 'n_estimators': 43}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost \n",
    "It is not too bad either."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  10 out of  25 | elapsed:    0.4s remaining:    0.6s\n",
      "[Parallel(n_jobs=8)]: Done  25 out of  25 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
       "         n_estimators=50, random_state=None),\n",
       "       fit_params=None, iid=True, n_jobs=8,\n",
       "       param_grid={'n_estimators': [10, 100, 1000, 10000, 50000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_absolute_error', verbose=True)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "ada = AdaBoostRegressor()\n",
    "param_ada = {'n_estimators': [10, 100, 1000, 10000, 50000]}\n",
    "ada_grid = GridSearchCV(ada, param_ada, cv=5, scoring = 'neg_mean_absolute_error', n_jobs=8, verbose=True)\n",
    "ada_grid.fit(whiteX, whitey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6006140187754887"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 100}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More linear models\n",
    "\n",
    "The following models are different types of linear models. Their performances, unsurprisingly, are similar.\n",
    "\n",
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  15 out of  15 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=8,\n",
       "       param_grid={'alpha': [0.1, 0.5, 1]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_absolute_error', verbose=True)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso()\n",
    "param_lasso = {'alpha': [0.1, 0.5, 1]}\n",
    "lasso_grid = GridSearchCV(lasso, param_lasso, cv=5, scoring = 'neg_mean_absolute_error', n_jobs=8, verbose=True)\n",
    "lasso_grid.fit(whiteX, whitey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.6248222827899399, {'alpha': 0.1})"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_grid.best_score_, lasso_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  10 out of  25 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  25 out of  25 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001),\n",
       "       fit_params=None, iid=True, n_jobs=8,\n",
       "       param_grid={'alpha': [0.1, 0.2, 0.3, 0.5, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_absolute_error', verbose=True)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge()\n",
    "param_ridge = {'alpha': [0.1, 0.2, 0.3, 0.5, 1]}\n",
    "ridge_grid = GridSearchCV(ridge, param_ridge, cv=5, scoring = 'neg_mean_absolute_error', n_jobs=8, verbose=True)\n",
    "ridge_grid.fit(whiteX, whitey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5959974639014806, {'alpha': 0.1})"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_grid.best_score_, ridge_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   6 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LinearRegression(copy_X=True, fit_intercept=True, n_jobs=8, normalize=False),\n",
       "       fit_params=None, iid=True, n_jobs=8,\n",
       "       param_grid={'normalize': [True, False]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_absolute_error', verbose=True)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression(n_jobs=8)\n",
    "param_lr = {'normalize': [True, False]}\n",
    "lr_grid = GridSearchCV(lr, param_lr, cv=5, scoring = 'neg_mean_absolute_error', n_jobs=8, verbose=True)\n",
    "lr_grid.fit(whiteX, whitey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5938098071626763, {'normalize': False})"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_grid.best_score_, lr_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  45 out of  45 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=8,\n",
       "       param_grid={'alpha': [0.1, 0.5, 1], 'l1_ratio': [0.5, 0.7, 0.3]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_absolute_error', verbose=True)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "enet = ElasticNet()\n",
    "param_enet = {'alpha': [0.1, 0.5, 1], 'l1_ratio': [0.5, 0.7, 0.3]}\n",
    "enet_grid = GridSearchCV(enet, param_enet, cv=5, scoring = 'neg_mean_absolute_error', n_jobs=8, verbose=True)\n",
    "enet_grid.fit(whiteX, whitey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.6237531427820255, {'alpha': 0.1, 'l1_ratio': 0.5})"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enet_grid.best_score_, enet_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
